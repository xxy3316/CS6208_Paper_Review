{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1680423138359,
     "user": {
      "displayName": "tianqianjin lin",
      "userId": "02429681390610284112"
     },
     "user_tz": -480
    },
    "id": "D5O0ZfaYdQ6k",
    "outputId": "77e2d565-6f6d-4e62-abe2-cb265e9933d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                         1.13.1+cu116\n",
      "torchaudio                    0.13.1+cu116\n",
      "torchsummary                  1.5.1\n",
      "torchtext                     0.14.1\n",
      "torchvision                   0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14075,
     "status": "ok",
     "timestamp": 1680423152431,
     "user": {
      "displayName": "tianqianjin lin",
      "userId": "02429681390610284112"
     },
     "user_tz": -480
    },
    "id": "XesI8zXidZKe",
    "outputId": "9576b6a2-0eae-4447-e22b-30c01bd0bb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.dgl.ai/wheels/cu116/repo.html\n",
      "Requirement already satisfied: dgl in /usr/local/lib/python3.9/dist-packages (1.0.2+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.27.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
      "Requirement already satisfied: dglgo in /usr/local/lib/python3.9/dist-packages (0.0.2)\n",
      "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.10.7)\n",
      "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.9/dist-packages (from dglgo) (2022.9.5)\n",
      "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.5.0)\n",
      "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (2.0.2)\n",
      "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (0.7.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.9/dist-packages (from dglgo) (0.17.21)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.9/dist-packages (from dglgo) (6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.2.2)\n",
      "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.3.5)\n",
      "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.9/dist-packages (from dglgo) (5.12.0)\n",
      "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.9/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.9/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
      "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.9/dist-packages (from numpydoc>=1.1.0->dglgo) (6.1.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.26.15)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.9/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n",
      "Requirement already satisfied: littleutils in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
      "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
      "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (6.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
      "Requirement already satisfied: docutils<0.20,>=0.18 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.19)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
      "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install  dgl -f https://data.dgl.ai/wheels/cu116/repo.html\n",
    "! pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78635,
     "status": "ok",
     "timestamp": 1680423231063,
     "user": {
      "displayName": "tianqianjin lin",
      "userId": "02429681390610284112"
     },
     "user_tz": -480
    },
    "id": "Twvldestcps1",
    "outputId": "1b541dcb-dd76-4234-f1cf-84dfd2dd2239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val Acc 0.842105 | Best Val Macro F1 0.802597\n",
      "Best Val Acc 0.842105 | Best Val Macro F1 0.821176\n",
      "Best Val Acc 0.868421 | Best Val Macro F1 0.856387\n",
      "Best Val Acc 0.815789 | Best Val Macro F1 0.786859\n",
      "Best Val Acc 0.894737 | Best Val Macro F1 0.885110\n",
      "Avg. Accuracy: 0.8526 ± 0.0268\n",
      "Avg. Macro F1: 0.8304 ± 0.0358\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dgl\n",
    "from dgl.data import GINDataset\n",
    "from dgl import function as fn\n",
    "from dgl.utils import expand_as_pair\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class GINConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        init_eps=0,\n",
    "        learn_eps=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # \"We can make ε a learnable parameter or a fixed scalar.\" refer to P5\n",
    "        self.eps = nn.Parameter(\n",
    "            torch.FloatTensor([init_eps]), \n",
    "            requires_grad=learn_eps\n",
    "        )\n",
    "\n",
    "        # accoding to section 5.1, 1-LAYER PERCEPTRONS ARE NOT SUFFICIENT\n",
    "        # we use 3-layer mlp here.\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        with graph.local_scope():\n",
    "            feat_src, feat_dst = expand_as_pair(feat, graph)\n",
    "            graph.srcdata['h'] = feat_src\n",
    "            graph.update_all(fn.copy_u('h', 'm'), fn.sum('m', 'neigh'))\n",
    "            rst = (1 + self.eps) * feat_dst + graph.dstdata['neigh']\n",
    "            rst = self.mlp(rst)\n",
    "        return rst\n",
    "\n",
    "\n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.ginlayers.append(\n",
    "                # accoding to P8, GIN-0 shows strong empirical performance\n",
    "                # so we set learn_eps to False\n",
    "                GINConv(\n",
    "                    input_dim  = input_dim if layer==0 else hidden_dim,\n",
    "                    hidden_dim = hidden_dim, \n",
    "                    learn_eps  = False\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        # pooling in each layer, refer to (the bottom of) page 5\n",
    "        # 'features from earlier iterations may sometimes generalize better'\n",
    "        # 'we use information from all depths/iterations of the model'\n",
    "        readout_dim = hidden_dim * num_layers + input_dim \n",
    "        # use a 3-layer mlp to do the prediction\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.BatchNorm1d(readout_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(readout_dim, hidden_dim),\n",
    "\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        # for the pooling layer\n",
    "        # refer to (the bottom of) page 5\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            hidden_rep.append(h)\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "\n",
    "        readout_lits = []\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            # print(g)\n",
    "            # print(SumPooling(g, h).shape)\n",
    "            # print('hhh')\n",
    "            # the number of nodes in each graph \n",
    "            n_node_per_graph_list = g.batch_num_nodes().cpu().numpy()\n",
    "            # node index in `h`\n",
    "            accumulated = [\n",
    "                sum(n_node_per_graph_list[:i+1]) \n",
    "                for i in range(len(n_node_per_graph_list))\n",
    "            ]\n",
    "            # print(accumulated)\n",
    "            start_end_idx_list = [\n",
    "                (0 if g_idx==0 else accumulated[g_idx-1], end)\n",
    "                for g_idx, end in enumerate(accumulated)\n",
    "                                \n",
    "            ]\n",
    "            # print(start_end_idx_list)\n",
    "            # n_graphs = len(n_node_per_graph_list)\n",
    "            # sum nodes embedding for each graph\n",
    "            readout = list(map(\n",
    "                lambda start_end: (h[start_end[0]:start_end[1]]).sum(dim=0), \n",
    "                start_end_idx_list\n",
    "            ))\n",
    "            \n",
    "            readout = torch.stack(readout, dim=0)\n",
    "            # print(n_node_per_graph_list)\n",
    "            # print(start_end_idx_list)\n",
    "            # print(readout)\n",
    "            # readout = self.pool(g, h)\n",
    "            # print(readout)\n",
    "            # return\n",
    "            # print(readout.shape)\n",
    "\n",
    "            # print(n_nodes_total,n_node_per_graph_list,n_graphs)\n",
    "            # return\n",
    "\n",
    "            readout_lits.append(readout)\n",
    "            # print('hhh2')\n",
    "            # print(i)\n",
    "        \n",
    "        # equation 4.2\n",
    "        readout = torch.cat(readout_lits, dim=-1)\n",
    "\n",
    "        pred = self.prediction_head(readout)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "def evaluate(dataloader, device, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        true_list = []\n",
    "        for batched_graph, labels in dataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feat = batched_graph.ndata.pop(\"attr\")\n",
    "            logits = model(batched_graph, feat)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "            pred_list.append(pred)\n",
    "            true_list.append(labels)\n",
    "        y_pred = torch.cat(pred_list,dim=-1).cpu().numpy()\n",
    "        y_true = torch.cat(true_list,dim=-1).cpu().numpy()\n",
    "        result = classification_report(\n",
    "            y_true, y_pred, output_dict=True, digits=4, zero_division=0\n",
    "        )\n",
    "    return {'accuracy': result['accuracy'], 'macro avg f1': result['macro avg']['f1-score']}\n",
    "\n",
    "\n",
    "def train(train_dataloader, val_dataloader, device, model):\n",
    "    # loss function, optimizer\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "    # training loop\n",
    "    best_acc = 0.\n",
    "    best_f1 = 0.\n",
    "    patience = 50\n",
    "    not_improved = 0\n",
    "    for epoch in range(10000):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch, (batched_graph, labels) in enumerate(train_dataloader):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feat = batched_graph.ndata.pop(\"attr\")\n",
    "            logits = model(batched_graph, feat)\n",
    "            loss = loss_fcn(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_result = evaluate(train_dataloader, device, model)\n",
    "        val_result = evaluate(val_dataloader, device, model)\n",
    "        # print(train_result['macro avg f1'])\n",
    "        print(\n",
    "            f\"\\rEpoch {epoch:05d} | Loss {total_loss / (batch + 1):.4f} | \"\n",
    "            + f\"Train Acc {train_result['accuracy']:.4f} | Val Acc {val_result['accuracy']:.4f} |\" \n",
    "            + f\"Train Macro F1 {train_result['macro avg f1']:.4f} | Val Macro F1 {val_result['macro avg f1']:.4f}\",\n",
    "            end = ''\n",
    "        )\n",
    "        if best_acc < val_result['accuracy']:\n",
    "            best_acc = val_result['accuracy']\n",
    "            best_f1 = val_result['macro avg f1']\n",
    "            not_improved = 0\n",
    "        else:\n",
    "            not_improved += 1\n",
    "        if not_improved > patience:\n",
    "            print(f\"\\rBest Val Acc {best_acc:.6f} | Best Val Macro F1 {best_f1:.6f}\")\n",
    "            return best_acc, best_f1\n",
    "            \n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, name:str, self_loop:bool, indices:list):\n",
    "        \n",
    "        # load dataset using dgl\n",
    "        self.dataset = GINDataset(name, self_loop)\n",
    "        # raw indices in the dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # mapping local index to the raw index\n",
    "        idx = self.indices[idx]\n",
    "        graph, label = self.dataset[idx]\n",
    "        return graph, label.reshape(1)\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "      list of dataset samples\n",
    "    \"\"\"\n",
    "    graphs, labels = zip(*data)\n",
    "\n",
    "    return dgl.batch(graphs), torch.cat(labels)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "name = \"MUTAG\" # \"MUTAG\", \"PTC\", \"NCI1\", \"PROTEINS\"\n",
    "self_loop = True\n",
    "raw_dataset = GINDataset(name, self_loop)\n",
    "num_samples = len(raw_dataset)\n",
    "in_size = raw_dataset.dim_nfeats\n",
    "out_size = raw_dataset.gclasses\n",
    "train_ratio = 0.6\n",
    "val_ratio = 1-train_ratio\n",
    "n_train = int(train_ratio*num_samples)\n",
    "hidden_size = 16\n",
    "n_layers = 5\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "best_acc_list, best_f1_list = [], []\n",
    "for n_round in range(5):\n",
    "    shuffle_idx = torch.randperm(num_samples)\n",
    "    train_idx = shuffle_idx[:n_train]\n",
    "    val_idx = shuffle_idx[n_train:]\n",
    "\n",
    "    train_dataset = GraphDataset(name, self_loop, train_idx)\n",
    "    val_dataset = GraphDataset(name, self_loop, val_idx)\n",
    "    # print()\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, \n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, collate_fn = collate_fn, \n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    model = GIN(in_size, hidden_size, out_size, n_layers).to(device)\n",
    "    best_acc, best_f1 = train(train_dataloader, val_dataloader, device, model)\n",
    "    best_acc_list.append(best_acc)\n",
    "    best_f1_list.append(best_f1)\n",
    "\n",
    "print(f\"Avg. Accuracy: {np.mean(best_acc_list):.4f} ± {np.std(best_acc_list):.4f}\")\n",
    "print(f\"Avg. Macro F1: {np.mean(best_f1_list):.4f} ± {np.std(best_f1_list):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9B8eT02MvzAwhsGZyobEB",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
